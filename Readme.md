# ğŸ§  MENTO BOT  
> An AI-Powered Coding Assistant built with **Streamlit**, **LangChain**, and **Ollama**

[![Streamlit](https://img.shields.io/badge/Built%20with-Streamlit-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io/)
[![LangChain](https://img.shields.io/badge/Powered%20by-LangChain-2E7D32?logo=python&logoColor=white)](https://python.langchain.com/)
[![Ollama](https://img.shields.io/badge/Model-Ollama-0A66C2?logo=ollama&logoColor=white)](https://ollama.ai/)
[![Python](https://img.shields.io/badge/Made%20with-Python-3776AB?logo=python&logoColor=white)](https://www.python.org/)

---

## ğŸ’¡ Overview

**MENTO BOT** is an intelligent coding assistant designed to help developers write, debug, and optimize Python code effortlessly.  
Built with **Streamlit** for an elegant UI and powered by **LangChain + Ollama** for local LLM interactions.

---

## ğŸš€ Features

âœ… **Multiple AI Modes**
- ğŸ§  *Default* â€“ Smart coding assistant  
- ğŸ *Bug Fixer* â€“ Identify and fix code issues  
- ğŸ§‘â€ğŸ’» *Code Reviewer* â€“ Suggest improvements and style fixes  
- âš¡ *Optimizer* â€“ Enhance performance and efficiency  

âœ… **Extras**
- ğŸ’¬ Persistent chat history  
- ğŸ’¾ Download chat logs  
- ğŸ§® Safe code execution  
- ğŸ¨ Custom dark UI theme  
- âš™ï¸ Local Ollama model integration

---

## ğŸ–¥ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| Frontend | Streamlit |
| AI Framework | LangChain |
| LLM Backend | Ollama |
| Language | Python 3.10+ |

---

## ğŸ§© Installation

Clone this repository:
```bash
git clone https://github.com/<your-username>/mento-bot.git
cd mento-bot
````

Install dependencies:

```bash
pip install -r requirements.txt
```

Start the Streamlit app:

```bash
streamlit run app.py
```

> ğŸ§  Make sure **Ollama** is running locally at `http://localhost:11434`.

---

## ğŸ§¾ Requirements

Create a `requirements.txt` file with:

```txt
streamlit
langchain
langchain-ollama
langchain-core
ollama
```

---

## âš™ï¸ How It Works

1. User enters a question or Python problem
2. The app builds a prompt chain using LangChain templates
3. Ollama model (`deepseek-r1:1.5b` by default) generates a structured reply
4. (Optional) The app safely executes Python code and displays results

---

## ğŸ§± Folder Structure

```
mento-bot/
 â”œâ”€â”€ app.py               # Main Streamlit application
 â”œâ”€â”€ requirements.txt     # Python dependencies
 â”œâ”€â”€ README.md            # Project documentation
 â””â”€â”€ .gitignore           # Ignored files and folders
```

---

## ğŸŒ Deployment (Streamlit Cloud)

You can easily host this app for free:

1. Push your project to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your GitHub repo
4. Select `app.py` as the entry file
5. Click **Deploy**

---

## ğŸ› ï¸ Troubleshooting

| Issue                   | Solution                                        |
| ----------------------- | ----------------------------------------------- |
| `ModuleNotFoundError`   | Run `pip install -r requirements.txt`           |
| Ollama connection error | Ensure Ollama server is running on port `11434` |
| Blank Streamlit page    | Clear cache: `streamlit cache clear`            |
| Git push rejected       | Run `git push -f origin main` if needed         |

---

## ğŸ¤ Contributing

Pull requests are welcome!
For major changes, please open an issue first to discuss what youâ€™d like to change.

---

## â¤ï¸ Acknowledgements

Special thanks to:

* [Streamlit](https://streamlit.io/)
* [LangChain](https://python.langchain.com/)
* [Ollama](https://ollama.ai/)
* Open-source contributors inspiring this project


